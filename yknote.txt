https://vllm.ai/

https://zhuanlan.zhihu.com/p/649977422
VLLM推理流程梳理（二）  BBuf  ==Done
https://zhuanlan.zhihu.com/p/649974825
VLLM推理流程梳理（一）  BBuf  ==Done

大模型推理服务框架vLLM要点简析 (上)
https://zhuanlan.zhihu.com/p/654259045

PagedAttention--大模型推理服务框架vLLM要点简析 (中)
https://zhuanlan.zhihu.com/p/655561941

CUDA PagedAttention kernel源码解析--大模型推理服务框架vLLM要点简析（下）
https://zhuanlan.zhihu.com/p/658233994

https://zhuanlan.zhihu.com/p/642852847
LLM推理框架1：exllama学习

https://zhuanlan.zhihu.com/p/649052223
LLM推理框架3：llama.cpp/koboldcpp学习

https://zhuanlan.zhihu.com/p/649588600
PagedAttention

https://zhuanlan.zhihu.com/p/655872477
如何利用vLLM框架快速部署LLama2

https://www.youtube.com/watch?v=uih4mtSl7Gs
vllm-project/vllm - Gource visualisation

https://zhuanlan.zhihu.com/p/645251151 ==架构描述，有图，非代码级别
vLLM框架top down概览

https://zhuanlan.zhihu.com/p/641999400  ==架构描述，有图，非代码级别
LLM 高速推理框架 vLLM 源代码分析 / vLLM Source Code Analysis

https://ai.oldpan.me/t/topic/174  LLM推理框架之vLLM  有动图

https://zhuanlan.zhihu.com/p/648759542
[Paper Reading] 针对 LLM Inference 的调度: Fast Distributed Inference Serving for Large Language Models

https://blog.csdn.net/qq_41185868/article/details/131428046
LLMs：《vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention》翻译与解读



PS C:\yk_repo\vllm\0.1.3> git checkout -b br0.1.3 aa84c92ef636e689b506b9842c712e5c615cc73a
Switched to a new branch 'br0.1.3'
PS C:\yk_repo\vllm\0.1.3> git branch
* br0.1.3
  main
PS C:\yk_repo\vllm\0.1.3>